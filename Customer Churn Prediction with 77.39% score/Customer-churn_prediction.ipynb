{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer churn prediction of a telephone company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "The purpose of this project is to predict the customer Churn Rate of a telephone company depending on the various metrics available in the data provided. The data set used for this project is in .csv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import numpy as np # library for linear algebra\n",
    "import pandas as pd # library fordata processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "import os\n",
    "import matplotlib.pyplot as plt#visualization\n",
    "from PIL import  Image\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns # library for visualization\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import io\n",
    "import plotly.offline as py  # library for visualization\n",
    "py.init_notebook_mode(connected=True) # library for visualization\n",
    "import plotly.graph_objs as go  # library for visualization\n",
    "import plotly.tools as tls # library for visualization\n",
    "import plotly.figure_factory as ff  # library for visualization\n",
    "import missingno as msn #library for finding missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'C:\\\\Users\\\\Thor\\\\Documents\\\\Projects\\\\Churn Prediction\\\\WA_Fn-UseC_-Telco-Customer-Churn.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-945a493d4162>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#lets load the dataset and display the first few lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Thor\\Documents\\Projects\\Churn Prediction\\WA_Fn-UseC_-Telco-Customer-Churn.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'C:\\\\Users\\\\Thor\\\\Documents\\\\Projects\\\\Churn Prediction\\\\WA_Fn-UseC_-Telco-Customer-Churn.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#lets load the dataset and display the first few lines \n",
    "df=pd.read_csv(r'C:\\Users\\Thor\\Documents\\Projects\\Churn Prediction\\WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets have a look at some basic attributes of the dataset we have\n",
    "#shape of the dataframe\n",
    "print('The shape of the DataFrame is ', df.shape)\n",
    "print('-'*100)\n",
    "#info of the dataframe\n",
    "print(df.info())\n",
    "print('-'*100)\n",
    "#columns of the dataframe\n",
    "print('The columns of df are\\n',df.columns.tolist())\n",
    "print('-'*100)\n",
    "#finding any missing values\n",
    "print('No of Missing Values per column\\n', df.isnull().sum())\n",
    "\n",
    "print('-'*100)\n",
    "#looking for unique values per column\n",
    "print('Unique values per columns\\n',df.nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using this missing values matrix to see if there is one, just for fun :-D\n",
    "msn.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After looking at the dataset, we can see we have 7043 rows and 21 columns. The last column we have is Churn which tells if a customer has churned or not( 0 being not, 1 being yes). So our objective is clear now, this is a classification problem(binary) and we need to predict the churn rate of the customer .\n",
    "#### We need to design a model using the existing data which can predict the churn rate of customers in future "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do some preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the totalcharges column is a sneaky boy, it has numerical like values but in string format,and it also has some white space values\n",
    "#lts fix it first\n",
    "df['TotalCharges']=df['TotalCharges'].replace(\" \",np.nan)\n",
    "df = df[df[\"TotalCharges\"].notnull()]\n",
    "df = df.reset_index()[df.columns]\n",
    "df[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most culomn has values in yes or no,but some entries are as 'no internet service'.lets rename it as No\n",
    "cols=['OnlineSecurity','OnlineBackup',\n",
    "'DeviceProtection'\n",
    ",'TechSupport',\n",
    "'StreamingTV',\n",
    "'StreamingMovies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols:\n",
    "    df[i]=df[i].replace({'No internet service' : 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SeniorCitizen\"] = df[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n",
    "df['MultipleLines']=df['MultipleLines'].replace({'No phone service':'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rechecked and found all good\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see tenure column has various values. Let us convert this column in group of values\n",
    "\n",
    "def tenure(df):\n",
    "    if df['tenure']<=12:\n",
    "        return 'Tenure_12'\n",
    "    elif (df['tenure']>12)&(df['tenure']<=24):\n",
    "        return 'Tenure_12_24'\n",
    "    elif (df['tenure']>24)&(df['tenure']<=48):\n",
    "        return 'Tenure_24_48'\n",
    "    elif (df['tenure']>48)&(df['tenure']<=60):\n",
    "        return 'Tenure_48_60'\n",
    "    elif df['tenure']>60:\n",
    "        return 'Tenure_60'\n",
    "    \n",
    "df['Tenure_grp']=df.apply(lambda df:tenure(df),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recheck again\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "## Attrition rate in pie plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us visualize how attrition rate is distributed\n",
    "labels=df['Churn'].value_counts().keys().tolist()\n",
    "values=df['Churn'].value_counts().values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use pie plot as below\n",
    "trace=go.Pie(labels=labels,\n",
    "            values=values,\n",
    "            marker=dict(colors=['royalblue','lime'],line=dict(color='white',width=1.3)),\n",
    "            rotation= 90,\n",
    "            hoverinfo='label+value+text',\n",
    "            hole=.5)\n",
    "layout=go.Layout(dict(title='Customer Attrition Rate'),\n",
    "                plot_bgcolor='rgb(243,243,243)',\n",
    "                paper_bgcolor='rgb(243,243,243)')\n",
    "data=[trace]\n",
    "fig=go.Figure(data=data,layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us divide the data into two sets, one contain the churn data and other contain the non churn\n",
    "churn     = df[df[\"Churn\"] == \"Yes\"]\n",
    "not_churn = df[df[\"Churn\"] == \"No\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will see how attrition rate is distributed for every column\n",
    "#we have extracted the categorical columns\n",
    "cat_cols=['gender',\n",
    "'SeniorCitizen',\n",
    "'Partner',\n",
    "'Dependents'\n",
    ",'tenure'\n",
    ",'PhoneService'\n",
    ",'MultipleLines'\n",
    ",'InternetService'\n",
    ",'OnlineSecurity'\n",
    ",'TechSupport'\n",
    ",'StreamingTV'\n",
    ",'StreamingMovies'\n",
    ",'PaperlessBilling'\n",
    ",'PaymentMethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot(column):\n",
    "\n",
    "\n",
    "        trace1=go.Pie(labels=churn[column].value_counts().keys().tolist(),\n",
    "                values=churn[column].value_counts().values.tolist(),\n",
    "                marker=dict(colors=['royalblue','lime'],line=dict(width=2)),\n",
    "                name = \"Churn Customers\",\n",
    "                domain  = dict(x = [0,.48]),\n",
    "                hoverinfo='label+percent+name',\n",
    "                hole=.5)\n",
    "        trace2=go.Pie(labels=not_churn[column].value_counts().keys().tolist(),\n",
    "                values=not_churn[column].value_counts().values.tolist(),\n",
    "                marker=dict(colors=['royalblue','lime'],line=dict(width=2)),\n",
    "                name= 'Non_Churn Customers',\n",
    "                domain  = dict(x = [.52,1]),\n",
    "                hoverinfo='label+percent+name',\n",
    "                hole=.5)\n",
    "\n",
    "     \n",
    "        layout=go.Layout(dict(title=column+' distribution in Customer Attrition Rate'),\n",
    "                         plot_bgcolor='rgb(243,243,243)',\n",
    "                         paper_bgcolor='rgb(243,243,243)',\n",
    "                         annotations = [dict(text = \"churn customers\",\n",
    "                                                font = dict(size = 13),\n",
    "                                                showarrow = False,\n",
    "                                                x = .15, y = .5),\n",
    "                                           dict(text = \"Non churn customers\",\n",
    "                                                font = dict(size = 13),\n",
    "                                                showarrow = False,\n",
    "                                                x = .88,y = .5\n",
    "                                               )\n",
    "                                          ] )\n",
    "                         \n",
    "     \n",
    "        data = [trace1,trace2]\n",
    "        fig  = go.Figure(data = data,layout = layout)\n",
    "        py.iplot(fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    pie_plot(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(column) :\n",
    "    trace1 = go.Histogram(x  = churn[column],\n",
    "                          histnorm= \"percent\",\n",
    "                          name = \"Churn Customers\",\n",
    "                          marker = dict(line = dict(width = .5,\n",
    "                                                    color = \"black\"\n",
    "                                                    )\n",
    "                                        ),\n",
    "                         opacity = .9 \n",
    "                         ) \n",
    "    \n",
    "    trace2 = go.Histogram(x  = not_churn[column],\n",
    "                          histnorm = \"percent\",\n",
    "                          name = \"Non churn customers\",\n",
    "                          marker = dict(line = dict(width = .5,\n",
    "                                              color = \"black\"\n",
    "                                             )\n",
    "                                 ),\n",
    "                          opacity = .9\n",
    "                         )\n",
    "    \n",
    "    data = [trace1,trace2]\n",
    "    layout = go.Layout(dict(title =column + \" distribution in customer attrition \",\n",
    "                            plot_bgcolor  = \"rgb(243,243,243)\",\n",
    "                            paper_bgcolor = \"rgb(243,243,243)\",\n",
    "                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                             title = column,\n",
    "                                             zerolinewidth=1,\n",
    "                                             ticklen=5,\n",
    "                                             gridwidth=2\n",
    "                                            ),\n",
    "                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                             title = \"percent\",\n",
    "                                             zerolinewidth=1,\n",
    "                                             ticklen=5,\n",
    "                                             gridwidth=2\n",
    "                                            ),\n",
    "                           )\n",
    "                      )\n",
    "    fig  = go.Figure(data=data,layout=layout)\n",
    "    \n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at histogram plot of the continuous data\n",
    "cols2=['MonthlyCharges'\n",
    ",'TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols2:\n",
    "    histogram(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#churn customers in tenure groups\n",
    "tg_ch  =  churn[\"Tenure_grp\"].value_counts().reset_index()\n",
    "tg_ch.columns  = [\"Tenure_grp\",\"count\"]\n",
    "tg_nch =  not_churn[\"Tenure_grp\"].value_counts().reset_index()\n",
    "tg_nch.columns = [\"Tenure_grp\",\"count\"]\n",
    "\n",
    "#bar - churn\n",
    "trace1 = go.Bar(x = tg_ch[\"Tenure_grp\"]  , y = tg_ch[\"count\"],\n",
    "                name = \"Churn Customers\",\n",
    "                marker = dict(line = dict(width = .5,color = \"black\")),\n",
    "                opacity = .9)\n",
    "\n",
    "#bar - not churn\n",
    "\n",
    "trace2 = go.Bar(x = tg_nch[\"Tenure_grp\"] , y = tg_nch[\"count\"],\n",
    "                name = \"Non Churn Customers\",\n",
    "                marker = dict(line = dict(width = .5,color = \"black\")),\n",
    "                opacity = .9)\n",
    "\n",
    "layout = go.Layout(dict(title = \"Customer attrition in tenure groups\",\n",
    "                        plot_bgcolor  = \"rgb(243,243,243)\",\n",
    "                        paper_bgcolor = \"rgb(243,243,243)\",\n",
    "                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                     title = \"tenure group\",\n",
    "                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n",
    "                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n",
    "                                     title = \"count\",\n",
    "                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n",
    "                       )\n",
    "                  )\n",
    "data = [trace1,trace2]\n",
    "fig  = go.Figure(data=data,layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i dont like scrolling up so I loaded the data again lol!!!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are half done with preprocessing\n",
    "#For a machine to be trained, it always eats numerical data, not categorical(coz high calories :-P), \n",
    "#so we need to convert the categorical data to numerical, and also we need to scale the numerical columns as otherwise it will misbehave\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = \"Tenure_grp\",axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The awesome and tricky part\n",
    "#customer id col\n",
    "Id_col     = ['customerID']\n",
    "#Target columns\n",
    "target_col = ['Churn']\n",
    "# extracting categorical columns\n",
    "cat_cols   = df.nunique()[df.nunique() < 6].keys().tolist()\n",
    "cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "# Extracting numerical columns\n",
    "num_cols   = [x for x in df.columns if x not in cat_cols + target_col + Id_col]\n",
    "# Extracting Binary columns with 2 values\n",
    "bin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\n",
    "#Extracting Columns more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "#Label encoding Binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "    \n",
    "#Duplicating columns for multi value columns\n",
    "df = pd.get_dummies(data = df,columns = multi_cols )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying \n",
    "print(cat_cols)\n",
    "print('--'*30)\n",
    "print(multi_cols)\n",
    "print('--'*30)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_telcom_og = df.copy()\n",
    "df = df.drop(columns = num_cols,axis = 1)\n",
    "df = df.merge(scaled,left_index=True,right_index=True,how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the correlation matrix\n",
    "corr=df.corr()\n",
    "f,ax=plt.subplots(figsize=(16,12))\n",
    "ax=sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets build now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting feature and target columns\n",
    "X=df.drop(columns=['customerID','Churn'],axis=1)\n",
    "\n",
    "y=df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeing how our target is distributed and we can see its pretty skewed\n",
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets build a naked model,without any optimization technique, not advisable because ..errrr i dont know\n",
    "classifiers={'LogisticRegression':LogisticRegression(),\n",
    "             'support vector':SVC(),\n",
    "             'Decision Tree':DecisionTreeClassifier(),\n",
    "             'RandomForest':RandomForestClassifier(),\n",
    "             'Naive Baes':GaussianNB()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for key,value in classifiers.items():\n",
    "        value.fit(X_train,y_train)\n",
    "        y_pred=value.predict(X_test)\n",
    "        score=accuracy_score(y_test,y_pred)\n",
    "        print('Classifier:',value.__class__.__name__ ,'has a  score of',round(score,2)*100,'%accuracy score')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import GridsearchCv to better train the model\n",
    "#trying Logistic Regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "logreg_params={'penalty':['l1','l2'],'C': [0.01,0.10,1,10,100]}\n",
    "grid_log_reg=GridSearchCV(LogisticRegression(),logreg_params,cv=5)\n",
    "grid_log_reg.fit(X_train,y_train)\n",
    "log_reg=grid_log_reg.best_estimator_\n",
    "print(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying knearest neighbour\n",
    "knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params,cv=5)\n",
    "grid_knears.fit(X_train, y_train)\n",
    "# KNears best estimator\n",
    "knears_neighbors = grid_knears.best_estimator_\n",
    "print(knears_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier\n",
    "svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "grid_svc = GridSearchCV(SVC(), svc_params,cv=5)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "# SVC best estimator\n",
    "svc = grid_svc.best_estimator_\n",
    "print(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree Classifier\n",
    "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "              \"min_samples_leaf\": list(range(5,7,1))}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params,cv=5)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# tree best estimator\n",
    "tree_clf = grid_tree.best_estimator_\n",
    "print(tree_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting with the best decision tree\n",
    "tr=DecisionTreeClassifier(criterion='gini', max_depth=2,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=5, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "tr.fit(X_train,y_train)\n",
    "y_pred=tr.predict(X_test)\n",
    "testing_score=accuracy_score(y_pred,y_test)\n",
    "print('Classifier Decision Tree has a testing score of',round(testing_score,2)*100,'%accuracy score')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting with the best logistic regression\n",
    "lr1=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "lr1.fit(X_train,y_train)\n",
    "y_pred=lr1.predict(X_test)\n",
    "testing_score=accuracy_score(y_pred,y_test)\n",
    "print('Classifier logistic Regression has a testing score of',round(testing_score,2)*100,'%accuracy score')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting with the best support vector \n",
    "svc1=SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "svc1.fit(X_train,y_train)\n",
    "svc1.predict(X_test)\n",
    "testing_score=accuracy_score(y_pred,y_test)\n",
    "print('Classifier Support vector machine has a testing score of',round(testing_score,2)*100,'%accuracy score')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see that we cn get only at max 80% accuracy with the classifiers\n",
    "#so lets drop the columns who has less variance\n",
    "#here we will take onl the top 10 features with highest variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "r=feat_importances.nlargest(10)\n",
    "\n",
    "data = [go.Bar(\n",
    "            x=r.index,\n",
    "            y=r.values,\n",
    "            marker=dict(\n",
    "                color='rgb(99,222,150)',\n",
    "                line=dict(\n",
    "                    color='rgb(8,48,255)',\n",
    "                    width=1.5),\n",
    "            ),\n",
    "            opacity=0.6\n",
    "        )]\n",
    "\n",
    "py.iplot(data, filename='feature importances')\n",
    "print(r.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#again lets check how our target variables are distributed\n",
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undersampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see the data is highly skewed\n",
    "#when we have skewed data, we can either undersample the majority class ,or oversample the minority class\n",
    "#at first part we will undersample the data and will take equal data of both class\n",
    "\n",
    "Number_of_Churn=len(df[df.Churn==1])\n",
    "Churn_indices=np.array(df[df.Churn==1].index)\n",
    "normal_indices=df[df.Churn==0].index\n",
    "random_non_Churn=np.random.choice(normal_indices,Number_of_Churn,replace=False)\n",
    "random_normal_indices=np.array(random_non_Churn)\n",
    "under_sample_index=np.concatenate([Churn_indices,random_normal_indices])\n",
    "under_sample_data=df.iloc[under_sample_index,:]\n",
    "under_sample_data.head()\n",
    "print('the percentage of not churn cases',len(under_sample_data[under_sample_data.Churn==0])/len(under_sample_data))\n",
    "print('the percentage of  Churn cases',len(under_sample_data[under_sample_data.Churn==1])/len(under_sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking only top 10 features in our undersampling data and starting the training and testing\n",
    "X_under=under_sample_data.loc[:,r.index]\n",
    "y_under=under_sample_data['Churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under,X_test_under,y_train_under,y_test_under=train_test_split(X_under,y_under,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers={'LogisticRegression':LogisticRegression(),\n",
    "             'support vector':SVC(),\n",
    "             'Decision Tree':DecisionTreeClassifier(),\n",
    "             'RandomForest':RandomForestClassifier(),\n",
    "             'Naive Baes':GaussianNB()\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "for key,value in classifiers.items():\n",
    "        value.fit(X_train_under,y_train_under)\n",
    "        y_pred_under=value.predict(X_test_under)\n",
    "        score=accuracy_score(y_test_under,y_pred_under)\n",
    "        print('Classifier:',value.__class__.__name__ ,'has a  score of',round(score,2)*100,'%accuracy score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "logreg_params={'penalty':['l1','l2'],'C': [0.01,0.10,1,10,100]}\n",
    "grid_log_reg=GridSearchCV(LogisticRegression(),logreg_params,cv=5)\n",
    "grid_log_reg.fit(X_train_under,y_train_under)\n",
    "log_reg=grid_log_reg.best_estimator_\n",
    "print(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check logistic regression on undersampled data\n",
    "lr_under=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "lr_under.fit(X_train_under,y_train_under)\n",
    "y_pred_under=lr_under.predict(X_test_under)\n",
    "testing_score=accuracy_score(y_pred_under,y_test_under)\n",
    "print('Classifier logistic Regression has a testing score of',round(testing_score,2)*100,'%accuracy score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hmmm not bad!!! lets try oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6fb8ff9ca5e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape of X_train dataset: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train dataset: \", X_train.shape)\n",
    "print(\"Shape of y_train dataset: \", y_train.shape)\n",
    "print(\"Shape of  X_test dataset: \", X_test.shape)\n",
    "print(\"Shape of  y_test dataset: \", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of X_train: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of y_train: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "logreg_params={'penalty':['l1','l2'],'C': [0.01,0.10,1,10,100]}\n",
    "grid_log_reg=GridSearchCV(LogisticRegression(),logreg_params,cv=5)\n",
    "grid_log_reg.fit(X_train_res,y_train_res)\n",
    "log_reg=grid_log_reg.best_estimator_\n",
    "print(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_under=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "lr_under.fit(X_train_res,y_train_res)\n",
    "y_pred=lr_under.predict(X_test)\n",
    "testing_score=accuracy_score(y_test,y_pred)\n",
    "print('Classifier logistic Regression has a testing score of',round(testing_score,2)*100,'%accuracy score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting with the best support vector \n",
    "svc1=SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm(model):\n",
    "    model.fit(X_train_res,y_train_res)\n",
    "    y_pred=model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    score=accuracy_score(y_test,y_pred)\n",
    "    print (\"\\n Classification report : \\n\",classification_report(y_test,y_pred))\n",
    "    print (\"Accuracy   Score : \",accuracy_score(y_test,y_pred))\n",
    "    #confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test,y_pred,labels=[0,1\n",
    "    ])\n",
    "    print('\\n\\n',conf_matrix)\n",
    "    #roc_auc_score\n",
    "    model_roc_auc = roc_auc_score(y_test,y_pred) \n",
    "    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "    fpr,tpr,thresholds = roc_curve(y_test,y_prob[:,1])\n",
    "    \n",
    "    #plotting confusion matrix and roc auc\n",
    "    \n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,7))\n",
    "    \n",
    "    sns.heatmap(conf_matrix,fmt='',cmap='RdYlGn',annot=True,linewidths=0.30,ax=ax1)\n",
    "    ax1.set_title='Confusion Matrix'\n",
    "    ax1.set_xlabel('Actual Values')\n",
    "    ax1.set_ylabel('Predicted Values')\n",
    "    sns.scatterplot(x=fpr,y=tpr,ax=ax2)\n",
    "    ax2.set_title='ROC CURVE'\n",
    "    ax2.set_xlabel('FPR')\n",
    "    ax2.set_ylabel('TPR')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm(lr_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We get a 74.6% accuracy score with logistic regression classifier using minority oversampling technique.Not bad for this simple Algorithm.\n",
    "\n",
    "\n",
    "\n",
    "### For the next  we will use  SVM, and lets see if this improves the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm(svc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We get a 72.32% accuracy score with SVM classifier using minority oversampling technique.Poor than the previous.\n",
    "\n",
    "\n",
    "\n",
    "### Let us try the best random forest classifier and check if this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "forest_params={'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000]}\n",
    "\n",
    "grid_forest=GridSearchCV(RandomForestClassifier(),forest_params,cv=5)\n",
    "grid_forest.fit(X_train,y_train)\n",
    "print(grid_forest.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rf=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=40, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=4, min_samples_split=5,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm(Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We get a 77.39% accuracy score with Random Forest classifier using minority oversampling technique.\n",
    "### Quite better than the previous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are still more  ways to play with the data and hyperparameters to improve the model performances,but for now,we stop here.\n",
    "### Thanks for the read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
